{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5983f8",
   "metadata": {},
   "source": [
    "# Working with LLM APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baab4269",
   "metadata": {},
   "source": [
    "In this notebook,  we will review how to use the OpenAI API Python SDK to send prompts to the following APIs:\n",
    "- OpenAI\n",
    "- Google Gemini\n",
    "- Anthropic \n",
    "\n",
    "\n",
    "General requirements:\n",
    "- APIs keys\n",
    "- Python SDKs for the APIs\n",
    "\n",
    "<br>\n",
    "<figure>\n",
    " <img src=\"assets/openai_sdk.png\" width=\"100%\" align=\"center\"/></a>\n",
    "<figcaption> The OpenAI API Python SDK workflow </figcaption>\n",
    "</figure>\n",
    "\n",
    "<br>\n",
    "\n",
    "Both Google Gemini and Anthropic have their own API SDKs, which are fairly similar to the OpenAI API, and you can find examples for using those SDKs in the notebook appendix.\n",
    "\n",
    "Let's start by import the os library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9367ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a49d9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "gemini_api_key = os.environ.get(\"GEMINI_API_KEY\")\n",
    "claude_api_key = os.getenv(\"CLAUDE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772db33b",
   "metadata": {},
   "source": [
    "We than define the following prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c6658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_prompt = \"\"\"\n",
    "I am working with a dataset that contains information about the Red30 Tech company's product sales online.\n",
    "I want to create a SQL query that calculates the total sales by state.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df75373f",
   "metadata": {},
   "source": [
    "Next, we define the number of tokens and temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66c43ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0\n",
    "max_tokens = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbbf10f",
   "metadata": {},
   "source": [
    "# The OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dec8b0",
   "metadata": {},
   "source": [
    "In this demo, we will review two models from the OpenAI API:\n",
    "- [GPT4.1](https://platform.openai.com/docs/models/gpt-4.1)\n",
    "- [GPT5](https://platform.openai.com/docs/models/gpt-5)\n",
    "\n",
    "We will use the `chat.completion` method to send a GET request to the OpenAI API. The method arguments may change over time and differ between different models or be deprecated. Therefore, please check the method's [documentation](https://platform.openai.com/docs/api-reference/chat) before using it.\n",
    "\n",
    "We will start by loading the API key and set the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c861e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key= openai_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ef31dd",
   "metadata": {},
   "source": [
    "> Note, the function has the OpenAI base URL as default, and therefore, we don't need to set it up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eca02c",
   "metadata": {},
   "source": [
    "### GPT4.1\n",
    "\n",
    "In the first example, we will use GPT4.1 model. We will use the `message` argument to set the prompt, the `temperature` and `max_completion_tokens` arguments to define he corresponding arguments. Last but not least, we define the model as `gpt-4.1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db6213ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_gpt4_1 = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": content_prompt}],\n",
    "    max_completion_tokens=max_tokens,\n",
    "    temperature=temperature,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be773a35",
   "metadata": {},
   "source": [
    "Let's review the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f66e9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-CBxSZsmSyxP0eCels4BOdHQrSLDYE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Certainly! To help you write the SQL query, I’ll assume your table is named `sales` and contains at least the following columns:\\n\\n- `state` (the state where the sale occurred)\\n- `sale_amount` (the amount of each sale)\\n\\nHere’s a basic SQL query to calculate the total sales by state:\\n\\n```sql\\nSELECT\\n  state,\\n  SUM(sale_amount) AS total_sales\\nFROM\\n  sales\\nGROUP BY\\n  state\\nORDER BY\\n  total_sales DESC;\\n```\\n\\n**Explanation:**\\n- `SUM(sale_amount)` calculates the total sales for each state.\\n- `GROUP BY state` groups the results by state.\\n- `ORDER BY total_sales DESC` sorts the results from highest to lowest total sales.\\n\\nIf your table or column names are different, adjust them accordingly. If you provide your actual table structure, I can tailor the query further!', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1756966207, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_daf5fcc80a', usage=CompletionUsage(completion_tokens=182, prompt_tokens=42, total_tokens=224, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(response_gpt4_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e6ac51",
   "metadata": {},
   "source": [
    "We will extract the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed3948e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! To help you write the SQL query, I’ll assume your table is named `sales` and contains at least the following columns:\n",
      "\n",
      "- `state` (the state where the sale occurred)\n",
      "- `sale_amount` (the amount of each sale)\n",
      "\n",
      "Here’s a basic SQL query to calculate the total sales by state:\n",
      "\n",
      "```sql\n",
      "SELECT\n",
      "  state,\n",
      "  SUM(sale_amount) AS total_sales\n",
      "FROM\n",
      "  sales\n",
      "GROUP BY\n",
      "  state\n",
      "ORDER BY\n",
      "  total_sales DESC;\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "- `SUM(sale_amount)` calculates the total sales for each state.\n",
      "- `GROUP BY state` groups the results by state.\n",
      "- `ORDER BY total_sales DESC` sorts the results from highest to lowest total sales.\n",
      "\n",
      "If your table or column names are different, adjust them accordingly. If you provide your actual table structure, I can tailor the query further!\n"
     ]
    }
   ],
   "source": [
    "print(response_gpt4_1.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483ea3c5",
   "metadata": {},
   "source": [
    "### GPT5\n",
    "\n",
    "Next, we will use the GTP5 model. Note that this models is a bit different from previous OpenAI models. It uses a different sampling method; therefore, the `temperature` is invalid. Instead, if you wish the model to return a deterministic response, you should use the `seed` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5580dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_gpt5 = client.chat.completions.create(\n",
    "    model=\"gpt-5\",\n",
    "    messages=[{\"role\": \"user\", \"content\": content_prompt}],\n",
    "    max_completion_tokens = max_tokens\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef740ac",
   "metadata": {},
   "source": [
    "Let's print the model response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c70fc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below are ready-to-use patterns. Pick the one that matches your schema, or tell me your table/column names and I’ll tailor it exactly.\n",
      "\n",
      "1) If you already store a per-order total and the state on the same row\n",
      "- Assumes table: orders(order_id, state, order_total, channel)\n",
      "SQL (SQL Server/PostgreSQL/MySQL compatible):\n",
      "SELECT\n",
      "  UPPER(TRIM(state)) AS state,\n",
      "  SUM(order_total) AS total_sales\n",
      "FROM orders\n",
      "WHERE channel = 'Online'            -- adjust/remove if you don’t have a channel column\n",
      "GROUP BY UPPER(TRIM(state))\n",
      "ORDER BY total_sales DESC;\n",
      "\n",
      "2) If state is in Customers and totals are in Orders\n",
      "- Assumes: orders(order_id, customer_id, order_total, channel), customers(customer_id, state)\n",
      "SELECT\n",
      "  UPPER(TRIM(c.state)) AS state,\n",
      "  SUM(o.order_total) AS total_sales\n",
      "FROM orders o\n",
      "JOIN customers c ON c.customer_id = o.customer_id\n",
      "WHERE o.channel = 'Online'          -- adjust as needed\n",
      "GROUP BY UPPER(TRIM(c.state))\n",
      "ORDER BY total_sales DESC;\n",
      "\n",
      "3) If you need to compute totals from line items\n",
      "- Assumes: orders(order_id, customer_id, ship_state, channel),\n",
      "  order_items(order_id, product_id, quantity, unit_price, discount),\n",
      "  customers(customer_id, state)\n",
      "- Uses ship_state when present; otherwise falls back to customer state.\n",
      "SELECT\n",
      "  UPPER(TRIM(COALESCE(o.ship_state, c.state))) AS state,\n",
      "  SUM(oi.quantity * oi.unit_price * (1 - COALESCE(oi.discount, 0))) AS total_sales\n",
      "FROM order_items oi\n",
      "JOIN orders o      ON o.order_id = oi.order_id\n",
      "LEFT JOIN customers c ON c.customer_id = o.customer_id\n",
      "WHERE o.channel = 'Online'          -- adjust/remove as needed\n",
      "GROUP BY UPPER(TRIM(COALESCE(o.ship_state, c.state)))\n",
      "ORDER BY total_sales DESC;\n",
      "\n",
      "Notes\n",
      "- Replace column/table names (state, order_total, channel, etc.) with your actual names.\n",
      "- Add a date filter if needed, e.g., WHERE order_date >= '2025-01-01'.\n",
      "- If you want to exclude missing/unknown states: add HAVING state IS NOT NULL AND state <> '' around the grouped alias, or use the expression again in HAVING.\n",
      "\n",
      "If you share a few column names or a small schema snippet, I’ll provide a precise query for the Red30 Tech dataset you have.\n"
     ]
    }
   ],
   "source": [
    "print(response_gpt5.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2de814c",
   "metadata": {},
   "source": [
    "# Google Gemini API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c882091",
   "metadata": {},
   "source": [
    "Let's now illustrate the use the OpenAI API SDK to call the Google Gemini API. You can find more details in the [document](https://ai.google.dev/gemini-api/docs/openai).\n",
    "\n",
    "Let's start by loading the API key, and set the client object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a489b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_client = OpenAI(\n",
    "    api_key= gemini_api_key,\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1297d79c",
   "metadata": {},
   "source": [
    "Next, we will use the same workflow as we did with the GPT4.1 model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87da16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_gemini = gemini_client.chat.completions.create(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    messages=[{\"role\": \"user\", \"content\": content_prompt}],\n",
    "    temperature=temperature,\n",
    "    max_completion_tokens=max_tokens,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2286232c",
   "metadata": {},
   "source": [
    "Let's print the model response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb304572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT\n",
      "    State,\n",
      "    SUM(Sales) AS TotalSales\n",
      "FROM\n",
      "    SalesData  -- Replace SalesData with the actual name of your table\n",
      "GROUP BY\n",
      "    State\n",
      "ORDER BY\n",
      "    TotalSales DESC;  -- Optional: Order the results by total sales in descending order\n",
      "```\n",
      "\n",
      "**Explanation:**\n",
      "\n",
      "* **`SELECT State, SUM(Sales) AS TotalSales`**: This selects the `State` column and calculates the sum of the `Sales` column, aliasing it as `TotalSales`.\n",
      "* **`FROM SalesData`**:  This specifies the table from which to retrieve the data.  **Important:**  Replace `SalesData` with the actual name of your table in your database.\n",
      "* **`GROUP BY State`**: This groups the rows based on the `State` column.  The `SUM(Sales)` function is then applied to each group, calculating the total sales for each state.\n",
      "* **`ORDER BY TotalSales DESC`**: This is optional. It orders the results in descending order based on the `TotalSales` column, so the state with the highest sales appears first.  If you want ascending order (lowest sales first), remove `DESC`.\n",
      "\n",
      "**Assumptions:**\n",
      "\n",
      "* Your table has a column named `State` representing the state where the sale occurred.\n",
      "* Your table has a column named `Sales` representing the sales amount (presumably a numeric type).\n",
      "* The table is named `SalesData` (or whatever the actual name is).\n",
      "\n",
      "**How to use it:**\n",
      "\n",
      "1. **Replace `SalesData` with the actual name of your table.**\n",
      "2. **Execute this query in your SQL database client (e.g., MySQL Workbench, pgAdmin, SQL Developer, etc.).**\n",
      "\n",
      "The query will return a result set with two columns: `State` and `TotalSales`, showing the total sales for each state in your dataset.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response_gemini.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665de233",
   "metadata": {},
   "source": [
    "# Anthropic Claude API\n",
    "\n",
    "Likewise, we can repeat the same workflow with the Anthropic Claude API. You can find more details in this [document](https://docs.anthropic.com/en/api/openai-sdk). Let's start by setting the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85c2461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_client = OpenAI(\n",
    "    api_key=claude_api_key,\n",
    "    base_url=\"https://api.anthropic.com/v1/\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea28128",
   "metadata": {},
   "source": [
    "Next, update the model setting and send a request to the Claude API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5ba80",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_claude = claude_client.chat.completions.create(\n",
    "    model=\"claude-opus-4-1-20250805\",\n",
    "    messages=[{\"role\": \"user\", \"content\": content_prompt}],\n",
    "    temperature=temperature,\n",
    "    max_completion_tokens=max_tokens,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6eca1",
   "metadata": {},
   "source": [
    "Last but not least, we will print the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd14ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_claude.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63d0a66",
   "metadata": {},
   "source": [
    "## Appendix\n",
    "\n",
    "In this section, we will review how to use the Google Gemini and Anthropic Python SDKs.\n",
    "\n",
    "\n",
    "### Working with the Google Gemini Python SDK \n",
    "\n",
    "Let's start by importing the `genai` and `types` methods from the `google` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613e0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02633625",
   "metadata": {},
   "source": [
    "Next, let's load the API key and set the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bda69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_client2 = genai.Client(api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de07abc9",
   "metadata": {},
   "source": [
    "We will use the `models.generate_content` method to send the prompt to the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b033b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_gemini2 = gemini_client2.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=content_prompt,\n",
    "    config=types.GenerateContentConfig(\n",
    "        max_output_tokens=max_tokens, temperature=temperature\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33e46c1",
   "metadata": {},
   "source": [
    "Let's print the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a414ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_gemini2.candidates[0].content.parts[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293434c8",
   "metadata": {},
   "source": [
    "### Working with the Anthropic Python SDK \n",
    "\n",
    "Let's start by loading the `anthropic` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3735bb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed43ee12",
   "metadata": {},
   "source": [
    "Next, we will set the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9a4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_client2 = anthropic.Anthropic(api_key=claude_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef3182c",
   "metadata": {},
   "source": [
    "And send the prompt to the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d25ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_claude2 = claude_client2.messages.create(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    max_tokens=1024,\n",
    "    messages=[{\"role\": \"user\", \"content\": content_prompt}],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e313f00f",
   "metadata": {},
   "source": [
    "Last but not least, we will print the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b7ab53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response_claude2.content[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a39fa",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "- OpenAI API [documentation](https://platform.openai.com/docs/api-reference/introduction)\n",
    "- Gemini API [documentation](https://ai.google.dev/gemini-api/docs)\n",
    "- Claude API [documentation](https://docs.anthropic.com/en/home)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-3.11-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
